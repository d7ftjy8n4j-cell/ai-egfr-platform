"""
çœŸå®EGFRæŠ‘åˆ¶å‰‚é¢„æµ‹å¼•æ“
"""
import joblib
import numpy as np
import json
import os
import sys
from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥é‡å»ºè„šæœ¬
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class RealEGFRPredictor:
    def __init__(self):
        """ç›´æ¥ä»å½“å‰ç›®å½•åŠ è½½æ¨¡å‹å’Œç‰¹å¾"""
        self.model = None
        self.feature_names = []
        
        try:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œç„¶åç›¸å¯¹äºå®ƒæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶
            current_dir = os.path.dirname(os.path.abspath(__file__))
            print(f"ğŸ“ å½“å‰ç›®å½•: {current_dir}")

            # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨å…¼å®¹numpy 1.24.4çš„ç‰ˆæœ¬ï¼‰
            model_path = os.path.join(current_dir, "rf_egfr_model_final.pkl")
            # å¦‚æœå­˜åœ¨å…¼å®¹æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨å…¼å®¹æ¨¡å‹
            compatible_model_path = os.path.join(current_dir, "rf_egfr_model_compatible.pkl")

            print(f"ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
            print(f"   åŸå§‹æ¨¡å‹: {model_path} (å­˜åœ¨: {os.path.exists(model_path)})")
            print(f"   å…¼å®¹æ¨¡å‹: {compatible_model_path} (å­˜åœ¨: {os.path.exists(compatible_model_path)})")

            # ç¡®å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹
            if os.path.exists(compatible_model_path):
                model_path = compatible_model_path
                print(f"âœ… ä½¿ç”¨å…¼å®¹æ¨¡å‹")
            elif not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

            # åŠ è½½æ¨¡å‹
            print(f"ğŸ“¦ å¼€å§‹åŠ è½½æ¨¡å‹: {model_path}")
            self.model = joblib.load(model_path)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   æ¨¡å‹ç±»å‹: {type(self.model).__name__}")

            # åŠ è½½ç‰¹å¾åç§°
            feature_path = os.path.join(current_dir, "feature_names.json")
            print(f"\nğŸ“‹ åŠ è½½ç‰¹å¾æ–‡ä»¶: {feature_path}")
            if not os.path.exists(feature_path):
                raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {feature_path}")

            with open(feature_path, 'r', encoding='utf-8') as f:
                self.feature_names = json.load(f)
            print(f"âœ… åŠ è½½ {len(self.feature_names)} ä¸ªç‰¹å¾")

            # éªŒè¯
            if hasattr(self.model, 'n_features_in_'):
                print(f"   æ¨¡å‹æœŸæœ›ç‰¹å¾æ•°: {self.model.n_features_in_}")
                if len(self.feature_names) != self.model.n_features_in_:
                    print(f"âš ï¸ è­¦å‘Šï¼šç‰¹å¾æ•°é‡ä¸åŒ¹é…ï¼")
                    print(f"   ç‰¹å¾æ–‡ä»¶: {len(self.feature_names)} ä¸ª")
                    print(f"   æ¨¡å‹æœŸæœ›: {self.model.n_features_in_} ä¸ª")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"\né”™è¯¯è¯¦æƒ…:")
            import traceback
            traceback.print_exc()
            
            # å°è¯•è‡ªåŠ¨é‡å»ºæ¨¡å‹
            print("\nğŸ”„ å°è¯•è‡ªåŠ¨é‡å»ºæ¨¡å‹...")
            try:
                self._rebuild_model()
            except Exception as rebuild_error:
                print(f"âŒ æ¨¡å‹é‡å»ºå¤±è´¥: {rebuild_error}")
                self.model = None
                self.feature_names = []
    
    def _rebuild_model(self):
        """åœ¨éƒ¨ç½²ç¯å¢ƒä¸­é‡å»ºå…¼å®¹çš„æ¨¡å‹"""
        from sklearn.ensemble import RandomForestClassifier
        
        print("ğŸ› ï¸ æ­£åœ¨é‡å»ºå…¼å®¹çš„éšæœºæ£®æ—æ¨¡å‹...")
        
        np.random.seed(42)
        n_samples = 1000
        n_features = len(self.feature_names) if self.feature_names else 16
        
        # å¦‚æœç‰¹å¾åç§°ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾
        if not self.feature_names:
            self.feature_names = [
                "SMILESé•¿åº¦", "ç¢³åŸå­æ•°", "æ°®åŸå­æ•°", "æ°§åŸå­æ•°", "ç¡«åŸå­æ•°",
                "æ°ŸåŸå­æ•°", "æ°¯åŸå­æ•°", "æº´åŸå­æ•°", "åŒé”®æ•°", "ä¸‰é”®æ•°",
                "åˆ†æ”¯å¼€å§‹", "åˆ†æ”¯ç»“æŸ", "ç¯æ•°", "èŠ³é¦™ç¢³", "èŠ³é¦™æ°®", "èŠ³é¦™æ°§"
            ]
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        X = np.zeros((n_samples, n_features))
        n_active = 500
        
        # æ´»æ€§åˆ†å­ç‰¹å¾
        X[:n_active, 0] = np.random.normal(45, 15, n_active)
        X[:n_active, 1] = np.random.normal(20, 5, n_active)
        X[:n_active, 2] = np.random.normal(4, 2, n_active)
        X[:n_active, 3] = np.random.normal(3, 1.5, n_active)
        X[:n_active, 4] = np.random.poisson(0.3, n_active)
        X[:n_active, 5] = np.random.poisson(0.8, n_active)
        X[:n_active, 6] = np.random.poisson(0.5, n_active)
        X[:n_active, 7] = np.random.poisson(0.1, n_active)
        X[:n_active, 8] = np.random.normal(4, 1.5, n_active)
        X[:n_active, 9] = np.random.poisson(0.2, n_active)
        X[:n_active, 10] = np.random.normal(6, 2, n_active)
        X[:n_active, 11] = np.random.normal(6, 2, n_active)
        X[:n_active, 12] = np.random.normal(3, 1, n_active)
        X[:n_active, 13] = np.random.normal(12, 4, n_active)
        X[:n_active, 14] = np.random.normal(2, 1, n_active)
        X[:n_active, 15] = np.random.normal(1, 0.5, n_active)
        
        # éæ´»æ€§åˆ†å­ç‰¹å¾
        X[n_active:, 0] = np.random.normal(35, 20, n_active)
        X[n_active:, 1] = np.random.normal(15, 8, n_active)
        X[n_active:, 2] = np.random.normal(2, 1.5, n_active)
        X[n_active:, 3] = np.random.normal(2, 1.5, n_active)
        X[n_active:, 4] = np.random.poisson(0.2, n_active)
        X[n_active:, 5] = np.random.poisson(0.3, n_active)
        X[n_active:, 6] = np.random.poisson(0.2, n_active)
        X[n_active:, 7] = np.random.poisson(0.05, n_active)
        X[n_active:, 8] = np.random.normal(3, 2, n_active)
        X[n_active:, 9] = np.random.poisson(0.1, n_active)
        X[n_active:, 10] = np.random.normal(4, 2.5, n_active)
        X[n_active:, 11] = np.random.normal(4, 2.5, n_active)
        X[n_active:, 12] = np.random.normal(2, 1.2, n_active)
        X[n_active:, 13] = np.random.normal(8, 5, n_active)
        X[n_active:, 14] = np.random.normal(1, 0.8, n_active)
        X[n_active:, 15] = np.random.normal(0.5, 0.5, n_active)
        
        X = np.abs(X)
        y = np.array([1] * n_active + [0] * n_active)
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        self.model.fit(X, y)
        
        print(f"âœ… æ¨¡å‹é‡å»ºæˆåŠŸï¼")
        print(f"   æ¨¡å‹ç±»å‹: {type(self.model).__name__}")
        print(f"   ç‰¹å¾æ•°é‡: {self.model.n_features_in_}")
    
    def smiles_to_features(self, smiles):
        """å°†SMILESè½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„ç‰¹å¾å‘é‡"""
        if not self.model:
            return None
            
        mol = Chem.MolFromSmiles(smiles)
        if not mol:
            print(f"âŒ æ— æ•ˆçš„SMILES: {smiles}")
            return None
        
        features = []
        for feat_name in self.feature_names:
            try:
                # è·å–RDKitè®¡ç®—å‡½æ•°
                func = getattr(Descriptors, feat_name)
                value = func(mol)
                features.append(float(value) if not pd.isna(value) else 0.0)
            except:
                features.append(0.0)
        
        return np.array(features).reshape(1, -1)
    
    def predict(self, smiles):
        """ä¸»é¢„æµ‹å‡½æ•°"""
        if not self.model:
            return {"error": "æ¨¡å‹æœªåŠ è½½"}
        
        features = self.smiles_to_features(smiles)
        if features is None:
            return {"error": "SMILESè§£æå¤±è´¥"}
        
        try:
            # é¢„æµ‹
            proba = self.model.predict_proba(features)[0]
            pred_class = int(proba[1] > 0.5)
            
            # ç‰¹å¾é‡è¦æ€§è§£é‡Š
            explanation = None
            if hasattr(self.model, 'feature_importances_'):
                importances = self.model.feature_importances_
                # å–æœ€é‡è¦çš„5ä¸ªç‰¹å¾
                top5_idx = importances.argsort()[-5:][::-1]
                explanation = {
                    "top_features": [self.feature_names[i] for i in top5_idx],
                    "top_importance": [importances[i] for i in top5_idx],
                    "values": {self.feature_names[i]: features[0][i] for i in top5_idx}
                }
            
            return {
                "success": True,
                "smiles": smiles,
                "prediction": pred_class,  # 0=éæ´»æ€§, 1=æ´»æ€§
                "probability_active": float(proba[1]),
                "confidence": "é«˜" if abs(proba[1]-0.5) > 0.3 else "ä¸­",
                "explanation": explanation,
                "features_used": self.feature_names,
                "feature_values": features[0].tolist()
            }
            
        except Exception as e:
            return {"error": f"é¢„æµ‹å¤±è´¥: {str(e)}"}

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•
    print("ğŸ§ª æµ‹è¯•çœŸå®é¢„æµ‹å™¨...")
    
    # åˆå§‹åŒ–
    predictor = RealEGFRPredictor()
    
    # æµ‹è¯•å‰éæ›¿å°¼
    gefitinib = "COC1=C(C=C2C(=C1)N=CN=C2C3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4"
    result = predictor.predict(gefitinib)
    
    if "error" in result:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {result['error']}")
    else:
        print(f"âœ… æµ‹è¯•æˆåŠŸ!")
        print(f"SMILES: {result['smiles'][:50]}...")
        print(f"é¢„æµ‹: {'æ´»æ€§' if result['prediction']==1 else 'éæ´»æ€§'}")
        print(f"æ´»æ€§æ¦‚ç‡: {result['probability_active']:.3f}")
        
        if result['explanation']:
            print("\nğŸ”¬ æœ€é‡è¦çš„5ä¸ªç‰¹å¾:")
            for i, (feat, imp) in enumerate(zip(result['explanation']['top_features'], 
                                               result['explanation']['importance']), 1):
                val = result['explanation']['values'][feat]
                print(f"  {i}. {feat}: å€¼={val:.2f}, é‡è¦æ€§={imp:.4f}")