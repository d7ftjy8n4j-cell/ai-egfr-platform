"""
gnn_predictor.py - GNNé¢„æµ‹å™¨ (é€‚é…æ‚¨è®­ç»ƒå¥½çš„EGFR GCNæ¨¡å‹)
ç”¨äºStreamlitåº”ç”¨é›†æˆï¼Œå°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†å­å›¾å¹¶è¿›è¡Œæ´»æ€§é¢„æµ‹
ä½œè€…ï¼šdadamingli
"""

import torch
import torch.nn.functional as F
from torch.nn import Linear, BatchNorm1d, Module, ModuleList
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data
from rdkit import Chem
import numpy as np
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GCNModel(Module):
    """
    ä¸æ‚¨è®­ç»ƒçš„GCNæ¨¡å‹å®Œå…¨ä¸€è‡´çš„æ¶æ„
    è¾“å…¥ç»´åº¦: 12, éšè—å±‚ç»´åº¦: 128, è¾“å‡ºç»´åº¦: 1
    """
    
    def __init__(self, input_dim=12, hidden_dim=128, num_layers=3, dropout=0.5):
        super(GCNModel, self).__init__()
        self.num_layers = num_layers
        self.dropout = dropout
        
        # åˆ›å»ºGCNå·ç§¯å±‚ - æ³¨æ„è¿™é‡Œçš„å±‚ç»“æ„
        self.convs = ModuleList()
        self.convs.append(GCNConv(input_dim, hidden_dim))
        self.convs.append(GCNConv(hidden_dim, hidden_dim))
        self.convs.append(GCNConv(hidden_dim, hidden_dim))
        
        # æ‰¹å½’ä¸€åŒ–å±‚
        self.bns = ModuleList()
        for _ in range(num_layers - 1):
            self.bns.append(BatchNorm1d(hidden_dim))
        
        # å…¨è¿æ¥å±‚
        self.lin1 = Linear(hidden_dim, hidden_dim // 2)
        self.lin2 = Linear(hidden_dim // 2, 1)
        
        logger.info(f"åˆå§‹åŒ–GCNæ¨¡å‹: {input_dim} -> {hidden_dim} -> 1")
    
    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        
        # GCNå±‚
        for i in range(self.num_layers - 1):
            x = self.convs[i](x, edge_index)
            x = self.bns[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        # æœ€åä¸€å±‚
        x = self.convs[-1](x, edge_index)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = global_mean_pool(x, batch)
        
        # å…¨è¿æ¥å±‚
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.lin2(x)
        
        return x

class GCNPredictor:
    """
    GCNé¢„æµ‹å™¨ - ç”¨äºStreamlitåº”ç”¨é›†æˆ
    åŠ è½½æ‚¨è®­ç»ƒå¥½çš„å®Œæ•´æ¨¡å‹: gcn_egfr_complete_model.pth
    """
    
    def __init__(self, model_path=None, device=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨

        å‚æ•°:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•çš„æ¨¡å‹æ–‡ä»¶
            device: è®¾å¤‡ ('cpu' æˆ– 'cuda')ï¼Œè‡ªåŠ¨æ£€æµ‹
        """
        # è®¾ç½®è®¾å¤‡
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)

        # è®¾ç½®æ¨¡å‹è·¯å¾„
        if model_path is None:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œç„¶åç›¸å¯¹äºå®ƒæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶
            current_dir = os.path.dirname(os.path.abspath(__file__))
            model_path = os.path.join(current_dir, 'gcn_egfr_best_model.pth')

        self.model_path = model_path
        self.model = None
        self.input_dim = 12  # ä¸æ‚¨çš„æ¨¡å‹è¾“å…¥ç»´åº¦ä¸€è‡´
        self.hidden_dim = 128  # ä¸æ‚¨çš„æ¨¡å‹éšè—å±‚ç»´åº¦ä¸€è‡´

        # åŠ è½½æ¨¡å‹
        self._load_model()
        logger.info(f"âœ… GCNé¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def _load_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {self.model_path}")

            logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")

            # å§‹ç»ˆä½¿ç”¨ state_dict æ–¹å¼åŠ è½½ï¼Œæ›´ç¨³å®šå¯é 
            # å…ˆåˆ›å»ºæ¨¡å‹æ¶æ„
            self.model = GCNModel(
                input_dim=self.input_dim,
                hidden_dim=self.hidden_dim,
                num_layers=3,
                dropout=0.5
            )

            # åŠ è½½ state_dict
            state_dict = torch.load(self.model_path, map_location=self.device, weights_only=False)

            # å°è¯•ä¸¥æ ¼æ¨¡å¼åŠ è½½
            try:
                self.model.load_state_dict(state_dict, strict=True)
                logger.info("âœ“ æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰")
            except Exception as e1:
                logger.warning(f"ä¸¥æ ¼æ¨¡å¼åŠ è½½å¤±è´¥: {e1}")
                # å°è¯•å®½æ¾æ¨¡å¼åŠ è½½
                try:
                    self.model.load_state_dict(state_dict, strict=False)
                    logger.info("âœ“ æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸï¼ˆå®½æ¾æ¨¡å¼ï¼Œéƒ¨åˆ†å±‚å¯èƒ½ä¸åŒ¹é…ï¼‰")
                except Exception as e2:
                    logger.error(f"æ¨¡å‹åŠ è½½å®Œå…¨å¤±è´¥: {e2}")
                    raise

            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.to(self.device)
            self.model.eval()

            # éªŒè¯æ¨¡å‹å‚æ•°
            total_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"æ¨¡å‹æ€»å‚æ•°é‡: {total_params:,}")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _smiles_to_graph(self, smiles):
        """
        å°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºPyTorch Geometricå›¾æ•°æ®
        
        å‚æ•°:
            smiles: SMILESå­—ç¬¦ä¸²
        
        è¿”å›:
            PyTorch Geometric Dataå¯¹è±¡
        """
        try:
            # è§£æSMILES
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                raise ValueError(f"æ— æ•ˆçš„SMILESå­—ç¬¦ä¸²: {smiles}")
            
            # ========== å…³é”®ï¼šæå–åŸå­ç‰¹å¾ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰==========
            # æ‚¨çš„æ¨¡å‹è¾“å…¥ç»´åº¦ä¸º12ï¼Œè¿™é‡Œæå–12ä¸ªç‰¹å¾
            atom_features = []
            for atom in mol.GetAtoms():
                # ç‰¹å¾åˆ—è¡¨ - ç»´åº¦å¿…é¡»ä¸º12
                features = [
                    float(atom.GetAtomicNum()),          # 1. åŸå­åºæ•°
                    float(atom.GetDegree()),             # 2. åº¦ï¼ˆè¿æ¥æ•°ï¼‰
                    float(atom.GetFormalCharge()),       # 3. å½¢å¼ç”µè·
                    float(atom.GetHybridization().real), # 4. æ‚åŒ–ç±»å‹
                    float(atom.GetIsAromatic()),         # 5. æ˜¯å¦æ˜¯èŠ³é¦™åŸå­
                    float(atom.GetTotalNumHs()),         # 6. æ€»æ°¢åŸå­æ•°
                    float(atom.GetImplicitValence()),    # 7. éšå¼ä»·
                    float(atom.GetNumRadicalElectrons()), # 8. è‡ªç”±åŸºç”µå­æ•°
                    float(atom.GetIsotope()),            # 9. åŒä½ç´ 
                    float(atom.GetMass() / 100.0),       # 10. åŸå­è´¨é‡ï¼ˆå½’ä¸€åŒ–ï¼‰
                    # è¡¥å……ç‰¹å¾åˆ°12ç»´
                    1.0 if atom.GetNumImplicitHs() > 0 else 0.0,  # 11. æ°¢é”®ä¾›ä½“ï¼ˆç®€åŒ–ï¼‰
                    1.0 if atom.GetAtomicNum() in [7, 8] else 0.0, # 12. æ°¢é”®å—ä½“ï¼ˆN, Oï¼‰
                ]
                
                # éªŒè¯ç‰¹å¾ç»´åº¦
                if len(features) != self.input_dim:
                    raise ValueError(f"ç‰¹å¾ç»´åº¦é”™è¯¯: æœŸæœ›{self.input_dim}, å®é™…{len(features)}")
                
                atom_features.append(features)
            
            # èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ
            x = torch.tensor(atom_features, dtype=torch.float)
            
            # ========== æ„å»ºè¾¹ç´¢å¼• ==========
            edge_indices = []
            for bond in mol.GetBonds():
                i = bond.GetBeginAtomIdx()
                j = bond.GetEndAtomIdx()
                # æ— å‘å›¾ï¼Œæ·»åŠ åŒå‘è¾¹
                edge_indices.append([i, j])
                edge_indices.append([j, i])
            
            # å¤„ç†å•åŸå­åˆ†å­ç‰¹æ®Šæƒ…å†µ
            if len(edge_indices) == 0:
                edge_indices.append([0, 0])
            
            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
            
            # ========== åˆ›å»ºDataå¯¹è±¡ ==========
            data = Data(
                x=x,
                edge_index=edge_index,
                smiles=smiles  # ä¿å­˜SMILESç”¨äºè°ƒè¯•
            )
            
            # æ·»åŠ batchç»´åº¦ï¼ˆå•ä¸ªåˆ†å­ï¼‰
            data.batch = torch.zeros(x.size(0), dtype=torch.long)
            
            logger.debug(f"å›¾æ•°æ®åˆ›å»ºæˆåŠŸ: {len(atom_features)}ä¸ªåŸå­, {len(edge_indices)//2}æ¡è¾¹")
            return data
            
        except Exception as e:
            logger.error(f"SMILESè½¬å›¾å¤±è´¥: {smiles} - {e}")
            raise
    
    def predict(self, smiles, return_details=False):
        """
        é¢„æµ‹å•ä¸ªåˆ†å­çš„EGFRæŠ‘åˆ¶æ´»æ€§
        
        å‚æ•°:
            smiles: SMILESå­—ç¬¦ä¸²
            return_details: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
            å­—å…¸æ ¼å¼çš„é¢„æµ‹ç»“æœ
        """
        start_time = torch.cuda.Event(enable_timing=True) if torch.cuda.is_available() else None
        if start_time:
            start_time.record()
        
        try:
            # 1. è½¬æ¢ä¸ºå›¾æ•°æ®
            data = self._smiles_to_graph(smiles)
            data = data.to(self.device)
            
            # 2. é¢„æµ‹
            with torch.no_grad():
                out = self.model(data)
                probability = torch.sigmoid(out).item()
                prediction = 1 if probability > 0.5 else 0
            
            # 3. è®¡ç®—ç½®ä¿¡åº¦
            if abs(probability - 0.5) > 0.3:
                confidence = "é«˜"
                confidence_score = 0.9
            elif abs(probability - 0.5) > 0.15:
                confidence = "ä¸­"
                confidence_score = 0.7
            else:
                confidence = "ä½"
                confidence_score = 0.5
            
            # 4. è®¡ç®—æ¨ç†æ—¶é—´
            inference_time = None
            if torch.cuda.is_available() and start_time:
                end_time = torch.cuda.Event(enable_timing=True)
                end_time.record()
                torch.cuda.synchronize()
                inference_time = start_time.elapsed_time(end_time)
            
            # 5. ç»„è£…ç»“æœ
            result = {
                "success": True,
                "smiles": smiles,
                "prediction": prediction,  # 0=éæ´»æ€§, 1=æ´»æ€§
                "prediction_label": "æ´»æ€§" if prediction == 1 else "éæ´»æ€§",
                "probability_active": probability,
                "probability_inactive": 1 - probability,
                "confidence": confidence,
                "confidence_score": confidence_score,
                "model_type": "GCN (å›¾å·ç§¯ç½‘ç»œ)",
                "model_auc": 0.8081,  # æ‚¨çš„æµ‹è¯•é›†AUC
                "model_accuracy": 0.7652,  # æ‚¨çš„æµ‹è¯•é›†å‡†ç¡®ç‡
                "timestamp": np.datetime64('now')
            }
            
            # æ·»åŠ è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœè¯·æ±‚ï¼‰
            if return_details:
                result.update({
                    "num_atoms": data.x.size(0),
                    "num_bonds": data.edge_index.size(1) // 2,
                    "inference_time_ms": inference_time,
                    "device": str(self.device),
                    "model_path": self.model_path
                })
            
            logger.info(f"é¢„æµ‹æˆåŠŸ: {smiles[:30]}... -> {result['prediction_label']} ({probability:.3f})")
            return result
            
        except Exception as e:
            error_result = {
                "success": False,
                "smiles": smiles,
                "error": str(e),
                "error_type": type(e).__name__
            }
            logger.error(f"é¢„æµ‹å¤±è´¥: {smiles[:30]}... - {e}")
            return error_result
    
    def batch_predict(self, smiles_list, batch_size=32):
        """
        æ‰¹é‡é¢„æµ‹å¤šä¸ªåˆ†å­
        
        å‚æ•°:
            smiles_list: SMILESå­—ç¬¦ä¸²åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        è¿”å›:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        total = len(smiles_list)
        
        logger.info(f"å¼€å§‹æ‰¹é‡é¢„æµ‹: {total}ä¸ªåˆ†å­")
        
        for i in range(0, total, batch_size):
            batch = smiles_list[i:i+batch_size]
            batch_results = []
            
            for smiles in batch:
                result = self.predict(smiles)
                batch_results.append(result)
            
            results.extend(batch_results)
            
            # æ‰“å°è¿›åº¦
            processed = min(i + batch_size, total)
            logger.info(f"è¿›åº¦: {processed}/{total} ({processed/total*100:.1f}%)")
        
        return results
    
    def test_model(self, test_smiles=None):
        """æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
        if test_smiles is None:
            test_smiles = "COC1=C(C=C2C(=C1)N=CN=C2C3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4"  # å‰éæ›¿å°¼
        
        logger.info("ğŸ§ª å¼€å§‹æ¨¡å‹æµ‹è¯•...")
        
        # æµ‹è¯•1: æ¨¡å‹æ¶æ„
        logger.info("1. æ£€æŸ¥æ¨¡å‹æ¶æ„...")
        logger.info(f"   æ¨¡å‹ç±»å‹: {type(self.model).__name__}")
        logger.info(f"   è¾“å…¥ç»´åº¦: {self.input_dim}")
        logger.info(f"   éšè—å±‚ç»´åº¦: {self.hidden_dim}")
        
        # æµ‹è¯•2: é¢„æµ‹åŠŸèƒ½
        logger.info("2. æµ‹è¯•é¢„æµ‹åŠŸèƒ½...")
        result = self.predict(test_smiles, return_details=True)
        
        if result["success"]:
            logger.info(f"   âœ… æµ‹è¯•é€šè¿‡!")
            logger.info(f"   æµ‹è¯•åˆ†å­: {test_smiles[:50]}...")
            logger.info(f"   é¢„æµ‹ç»“æœ: {result['prediction_label']}")
            logger.info(f"   æ´»æ€§æ¦‚ç‡: {result['probability_active']:.4f}")
            logger.info(f"   ç½®ä¿¡åº¦: {result['confidence']}")
            
            if "inference_time_ms" in result and result["inference_time_ms"] is not None:
                logger.info(f"   æ¨ç†æ—¶é—´: {result['inference_time_ms']:.1f} ms")
        else:
            logger.error(f"   âŒ æµ‹è¯•å¤±è´¥: {result['error']}")
        
        return result

# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§¬ GNNé¢„æµ‹å™¨æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    try:
        predictor = GCNPredictor()
        print("âœ… é¢„æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)
    
    # æµ‹è¯•æ¨¡å‹
    test_result = predictor.test_model()
    
    # ç¤ºä¾‹é¢„æµ‹
    print("\nğŸ“‹ ç¤ºä¾‹é¢„æµ‹:")
    examples = [
        "Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1",  # é«˜æ´»æ€§EGFRæŠ‘åˆ¶å‰‚
        "CC(=O)OC1=CC=CC=C1C(=O)O",           # é˜¿å¸åŒ¹æ— (éæ´»æ€§)
        "CN1C=NC2=C1C(=O)N(C(=O)N2C)C",       # å’–å•¡å›  (éæ´»æ€§)
    ]
    
    for smiles in examples:
        result = predictor.predict(smiles)
        status = "âœ…" if result["success"] else "âŒ"
        label = result.get("prediction_label", "é”™è¯¯")
        prob = result.get("probability_active", 0)
        print(f"  {status} {smiles[:30]:30} -> {label:8} ({prob:.3f})")
    
    print("\n" + "=" * 60)
    print("ğŸš€ GNNé¢„æµ‹å™¨å‡†å¤‡å°±ç»ªï¼Œå¯é›†æˆåˆ°Streamlitåº”ç”¨!")
    print("=" * 60)