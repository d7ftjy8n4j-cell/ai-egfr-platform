"""
advanced_chem_insight.py - é«˜çº§åŒ–å­¦æ´å¯Ÿæ¨¡å—ï¼ˆåŸºäºä¼˜åŒ–ç‰ˆT004+T033ï¼‰
ä¸ºEGFRé¢„æµ‹ç³»ç»Ÿæä¾›ä¸“ä¸šçº§çš„ç›¸ä¼¼æ€§åˆ†æå’Œåˆ†å­è¡¨ç¤ºå¯¹æ¯”
ç‰ˆæœ¬: 2.0.0 - åŸºäºTeachOpenCADD T004ä¼˜åŒ–ç‰ˆæœ¬æ„å»º
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import base64
from io import BytesIO
import matplotlib.pyplot as plt
from matplotlib.ticker import PercentFormatter
from rdkit import Chem, DataStructs
from rdkit.Chem import (
    PandasTools,
    Draw,
    Descriptors,
    MACCSkeys,
    rdFingerprintGenerator,
    Fragments
)
from rdkit.Chem.Draw import rdDepictor
import matplotlib
matplotlib.use('Agg')
import warnings
warnings.filterwarnings('ignore')
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import os
import random

# é…ç½®è®¾ç½®
rdDepictor.SetPreferCoordGen(True)

# å®šä¹‰é¡¹ç›®åŸºç¡€ç›®å½•
BASE_DIR = Path(__file__).parent

@dataclass
class ScreeningConfig:
    """è™šæ‹Ÿç­›é€‰é…ç½®"""
    pic50_cutoff: float = 6.3
    fp_radius: int = 2
    fp_size: int = 2048
    top_n_results: int = 10
    similarity_threshold: float = 0.7

class AdvancedMolecularSimilarity:
    """é«˜çº§åˆ†å­ç›¸ä¼¼æ€§è®¡ç®—ï¼ˆåŸºäºä¼˜åŒ–ç‰ˆT004ï¼‰"""
    
    def __init__(self, config: ScreeningConfig = None):
        self.config = config or ScreeningConfig()
        self.morgan_generator = rdFingerprintGenerator.GetMorganGenerator(
            radius=self.config.fp_radius, 
            fpSize=self.config.fp_size
        )
    
    def smiles_to_mol(self, smiles: str) -> Optional[Chem.rdchem.Mol]:
        """å®‰å…¨åœ°å°†SMILESè½¬æ¢ä¸ºåˆ†å­å¯¹è±¡"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                # å°è¯•æ¸…ç†SMILES
                smiles_clean = smiles.split()[0].strip()
                mol = Chem.MolFromSmiles(smiles_clean)
            return mol
        except Exception:
            return None
    
    def calculate_descriptors(self, molecules_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—åˆ†å­æè¿°ç¬¦ï¼ˆåŒ…å«é”™è¯¯å¤„ç†ï¼‰"""
        df = molecules_df.copy()
        
        try:
            # 1Dæè¿°ç¬¦
            df["molecule_weight"] = df["ROMol"].apply(Descriptors.MolWt)
            df["logp"] = df["ROMol"].apply(Descriptors.MolLogP)
            df["hbd"] = df["ROMol"].apply(Descriptors.NumHDonors)
            df["hba"] = df["ROMol"].apply(Descriptors.NumHAcceptors)
            df["rotatable_bonds"] = df["ROMol"].apply(Descriptors.NumRotatableBonds)
            
            # 2DæŒ‡çº¹
            df["maccs_fp"] = df["ROMol"].apply(MACCSkeys.GenMACCSKeys)
            df["morgan_fp"] = df["ROMol"].apply(self.morgan_generator.GetFingerprint)
            df["morgan_count_fp"] = df["ROMol"].apply(
                self.morgan_generator.GetCountFingerprint
            )
            
            # æ‹“æ‰‘ææ€§è¡¨é¢ç§¯
            df["tpsa"] = df["ROMol"].apply(Descriptors.TPSA)
            
        except Exception as e:
            st.warning(f"æè¿°ç¬¦è®¡ç®—éƒ¨åˆ†å¤±è´¥: {e}")
        
        return df
    
    def calculate_similarities(self, 
                             query_mol: Chem.rdchem.Mol,
                             molecules_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æŸ¥è¯¢åˆ†å­ä¸æ•°æ®é›†ä¸­æ‰€æœ‰åˆ†å­çš„ç›¸ä¼¼æ€§ï¼ˆå¤šæŒ‡æ ‡ï¼‰"""
        if query_mol is None:
            raise ValueError("æŸ¥è¯¢åˆ†å­æ— æ•ˆ")
        
        df = molecules_df.copy()
        
        try:
            # ç”ŸæˆæŸ¥è¯¢åˆ†å­æŒ‡çº¹
            maccs_fp_query = MACCSkeys.GenMACCSKeys(query_mol)
            morgan_fp_query = self.morgan_generator.GetFingerprint(query_mol)
            morgan_count_fp_query = self.morgan_generator.GetCountFingerprint(query_mol)
            
            # æå–æ•°æ®é›†æŒ‡çº¹åˆ—è¡¨
            maccs_fps = df["maccs_fp"].tolist()
            morgan_fps = df["morgan_fp"].tolist()

            # å®‰å…¨è·å–è®¡æ•°æŒ‡çº¹ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
            if "morgan_count_fp" in df.columns:
                morgan_count_fps = df["morgan_count_fp"].tolist()
            else:
                morgan_count_fps = df["ROMol"].apply(
                    self.morgan_generator.GetCountFingerprint
                ).tolist()
            
            # è®¡ç®—MACCSç›¸ä¼¼åº¦
            df["tanimoto_maccs"] = DataStructs.BulkTanimotoSimilarity(
                maccs_fp_query, maccs_fps
            )
            df["dice_maccs"] = DataStructs.BulkDiceSimilarity(
                maccs_fp_query, maccs_fps
            )
            
            # è®¡ç®—Morganç›¸ä¼¼åº¦
            df["tanimoto_morgan"] = DataStructs.BulkTanimotoSimilarity(
                morgan_fp_query, morgan_fps
            )
            df["dice_morgan"] = DataStructs.BulkDiceSimilarity(
                morgan_fp_query, morgan_fps
            )
            
            # è®¡æ•°æŒ‡çº¹ç›¸ä¼¼åº¦
            df["tanimoto_morgan_count"] = DataStructs.BulkTanimotoSimilarity(
                morgan_count_fp_query, morgan_count_fps
            )
            
            # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
            df["avg_similarity"] = df[["tanimoto_morgan", "tanimoto_maccs"]].mean(axis=1)
            
        except Exception as e:
            st.error(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
        
        return df
    
    def get_similarity_statistics(self, df: pd.DataFrame) -> Dict:
        """è·å–ç›¸ä¼¼åº¦ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "morgan_mean": df["tanimoto_morgan"].mean(),
            "morgan_std": df["tanimoto_morgan"].std(),
            "morgan_max": df["tanimoto_morgan"].max(),
            "maccs_mean": df["tanimoto_maccs"].mean(),
            "maccs_std": df["tanimoto_maccs"].std(),
            "maccs_max": df["tanimoto_maccs"].max(),
            "high_similarity_count": (df["tanimoto_morgan"] > 0.7).sum(),
            "active_high_similarity": ((df["tanimoto_morgan"] > 0.7) & 
                                     (df.get("pIC50", 0) >= self.config.pic50_cutoff)).sum()
        }
        return stats

class AdvancedVisualization:
    """é«˜çº§å¯è§†åŒ–å·¥å…·"""
    
    @staticmethod
    def visualize_similarity_distribution(df: pd.DataFrame, 
                                        figsize: Tuple[int, int] = (14, 10)) -> plt.Figure:
        """å¯è§†åŒ–ç›¸ä¼¼åº¦åˆ†å¸ƒï¼ˆå¢å¼ºç‰ˆï¼‰"""
        fig, axes = plt.subplots(2, 3, figsize=figsize)
        
        # ç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾
        df["tanimoto_maccs"].hist(ax=axes[0, 0], bins=50, alpha=0.7, 
                                 color='skyblue', edgecolor='black')
        axes[0, 0].set_title("MACCSæŒ‡çº¹ç›¸ä¼¼åº¦åˆ†å¸ƒ", fontsize=12, fontweight='bold')
        axes[0, 0].set_xlabel("Tanimotoç³»æ•°")
        axes[0, 0].set_ylabel("åˆ†å­æ•°é‡")
        axes[0, 0].axvline(x=0.7, color='red', linestyle='--', alpha=0.7, 
                          label='é«˜ç›¸ä¼¼åº¦é˜ˆå€¼')
        axes[0, 0].legend()
        
        df["tanimoto_morgan"].hist(ax=axes[0, 1], bins=50, alpha=0.7, 
                                  color='orange', edgecolor='black')
        axes[0, 1].set_title("MorganæŒ‡çº¹ç›¸ä¼¼åº¦åˆ†å¸ƒ", fontsize=12, fontweight='bold')
        axes[0, 1].set_xlabel("Tanimotoç³»æ•°")
        axes[0, 1].axvline(x=0.7, color='red', linestyle='--', alpha=0.7)
        
        # æ´»æ€§ä¸éæ´»æ€§çš„ç›¸ä¼¼åº¦å¯¹æ¯”ç®±çº¿å›¾
        if "pIC50" in df.columns:
            df["activity_status"] = df["pIC50"].apply(
                lambda x: "æ´»æ€§" if x >= 6.3 else "éæ´»æ€§"
            )
            
            data_for_box = []
            labels = []
            for status in ["æ´»æ€§", "éæ´»æ€§"]:
                subset = df[df["activity_status"] == status]
                if len(subset) > 0:
                    data_for_box.append(subset["tanimoto_morgan"].values)
                    labels.append(status)
            
            if data_for_box:
                axes[0, 2].boxplot(data_for_box, labels=labels, 
                                  patch_artist=True,
                                  boxprops=dict(facecolor='lightgreen', alpha=0.7))
                axes[0, 2].set_title("æ´»æ€§çŠ¶æ€ç›¸ä¼¼åº¦å¯¹æ¯”", fontsize=12, fontweight='bold')
                axes[0, 2].set_ylabel("Tanimotoç³»æ•°")
                axes[0, 2].grid(True, alpha=0.3)
        
        # ç›¸ä¼¼åº¦æ¯”è¾ƒæ•£ç‚¹å›¾
        df.plot.scatter(x="tanimoto_maccs", y="tanimoto_morgan", 
                       ax=axes[1, 0], alpha=0.6, c=df.get("pIC50", 50), 
                       cmap='viridis', colorbar=True)
        axes[1, 0].plot([0, 1], [0, 1], 'k--', alpha=0.5)
        axes[1, 0].set_xlabel("MACCSç›¸ä¼¼åº¦")
        axes[1, 0].set_ylabel("Morganç›¸ä¼¼åº¦")
        axes[1, 0].set_title("æŒ‡çº¹æ–¹æ³•æ¯”è¾ƒ", fontsize=12, fontweight='bold')
        
        # ç›¸ä¼¼åº¦ä¸æ´»æ€§çš„å…³ç³»
        if "pIC50" in df.columns:
            axes[1, 1].scatter(df["tanimoto_morgan"], df["pIC50"], 
                              alpha=0.6, c='purple')
            axes[1, 1].set_xlabel("Morganç›¸ä¼¼åº¦")
            axes[1, 1].set_ylabel("pIC50")
            axes[1, 1].set_title("ç›¸ä¼¼åº¦ä¸æ´»æ€§å…³ç³»", fontsize=12, fontweight='bold')
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            try:
                z = np.polyfit(df["tanimoto_morgan"], df["pIC50"], 1)
                p = np.poly1d(z)
                axes[1, 1].plot(df["tanimoto_morgan"], p(df["tanimoto_morgan"]), 
                               "r--", alpha=0.8)
            except:
                pass
        
        # æŒ‡çº¹ç±»å‹å¯¹æ¯”é›·è¾¾å›¾
        ax_radar = fig.add_subplot(2, 3, 6, projection='polar')
        
        fp_types = ["MACCS", "Morgan", "è®¡æ•°æŒ‡çº¹"]
        avg_similarities = [
            df["tanimoto_maccs"].mean(),
            df["tanimoto_morgan"].mean(),
            df.get("tanimoto_morgan_count", pd.Series([0])).mean()
        ]
        
        angles = np.linspace(0, 2 * np.pi, len(fp_types), endpoint=False).tolist()
        avg_similarities += avg_similarities[:1]
        angles += angles[:1]
        
        ax_radar.plot(angles, avg_similarities, 'o-', linewidth=2)
        ax_radar.fill(angles, avg_similarities, alpha=0.25)
        ax_radar.set_xticks(angles[:-1])
        ax_radar.set_xticklabels(fp_types)
        ax_radar.set_title("æŒ‡çº¹æ–¹æ³•æ•ˆæœå¯¹æ¯”", fontsize=12, fontweight='bold', y=1.1)
        ax_radar.set_ylim(0, 1)
        
        plt.tight_layout()
        return fig
    
    @staticmethod
    def create_enrichment_plot(df: pd.DataFrame,
                              similarity_measure: str = "tanimoto_morgan",
                              pic50_cutoff: float = 6.3) -> plt.Figure:
        """åˆ›å»ºå¯Œé›†æ›²çº¿å›¾"""
        # æ£€æŸ¥pIC50åˆ—æ˜¯å¦å­˜åœ¨
        if "pIC50" not in df.columns:
            st.warning("æ•°æ®é›†ç¼ºå°‘pIC50åˆ—ï¼Œæ— æ³•ç”Ÿæˆå¯Œé›†æ›²çº¿")
            fig, ax = plt.subplots(figsize=(10, 8))
            ax.text(0.5, 0.5, "æ•°æ®ç¼ºå°‘æ´»æ€§å€¼(pIC50)åˆ—", ha='center', va='center', fontsize=14)
            return fig

        # ç¡®ä¿æ•°æ®æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
        df_sorted = df.sort_values(similarity_measure, ascending=False).reset_index(drop=True)
        
        # è®¡ç®—ç´¯ç§¯ç»Ÿè®¡é‡
        n_total = len(df_sorted)
        n_actives = (df_sorted["pIC50"] >= pic50_cutoff).sum()
        
        # è®¡ç®—ç´¯ç§¯æ´»æ€§åˆ†å­æ•°
        df_sorted["cumulative_actives"] = (df_sorted["pIC50"] >= pic50_cutoff).cumsum()
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        df_sorted["%_ranked_dataset"] = (df_sorted.index + 1) / n_total * 100
        df_sorted["%_true_actives_identified"] = df_sorted["cumulative_actives"] / n_actives * 100
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # ç»˜åˆ¶å¯Œé›†æ›²çº¿
        ax.plot(df_sorted["%_ranked_dataset"],
                df_sorted["%_true_actives_identified"],
                label=f"{similarity_measure}",
                color='blue',
                linewidth=2.5,
                alpha=0.8)
        
        # æœ€ä¼˜æ›²çº¿
        ratio_actives = n_actives / n_total * 100
        x_optimal = [0, ratio_actives, 100]
        y_optimal = [0, 100, 100]
        ax.plot(x_optimal, y_optimal, 
                label="æœ€ä¼˜æ›²çº¿", 
                color='green', 
                linestyle='--',
                linewidth=2)
        
        # éšæœºæ›²çº¿
        ax.plot([0, 100], [0, 100], 
                label="éšæœºæ›²çº¿", 
                color='grey', 
                linestyle=':',
                linewidth=2)
        
        # ç¾åŒ–å›¾å½¢
        ax.set_xlabel("æ’åºæ•°æ®ç™¾åˆ†æ¯” (%)", fontsize=12, fontweight='bold')
        ax.set_ylabel("è¯†åˆ«æ´»æ€§åˆ†å­ç™¾åˆ†æ¯” (%)", fontsize=12, fontweight='bold')
        ax.set_title("è™šæ‹Ÿç­›é€‰å¯Œé›†æ›²çº¿", fontsize=14, fontweight='bold')
        ax.legend(loc='lower right', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # è®¾ç½®ç™¾åˆ†æ¯”æ ¼å¼
        ax.xaxis.set_major_formatter(PercentFormatter())
        ax.yaxis.set_major_formatter(PercentFormatter())
        
        # æ·»åŠ æ ‡æ³¨
        ax.text(10, 90, f"æ´»æ€§åˆ†å­: {n_actives}/{n_total}", 
                fontsize=10, bbox=dict(boxstyle="round,pad=0.3", 
                                      facecolor="yellow", alpha=0.5))
        
        plt.tight_layout()
        return fig
    
    @staticmethod
    def visualize_top_molecules(query_mol: Chem.rdchem.Mol,
                              top_molecules_df: pd.DataFrame,
                              n_mols_per_row: int = 4,
                              sub_img_size: Tuple[int, int] = (250, 200)) -> str:
        """å¯è§†åŒ–æŸ¥è¯¢åˆ†å­å’Œæ’åé å‰çš„åˆ†å­ï¼ˆè¿”å›Base64ç¼–ç çš„å›¾ç‰‡ï¼‰"""
        legends = [f"æŸ¥è¯¢åˆ†å­"]
        
        for idx, (_, row) in enumerate(top_molecules_df.iterrows(), 1):
            activity = row.get('pIC50', 'N/A')
            similarity = row.get('tanimoto_morgan', 0)
            
            if isinstance(activity, (int, float)):
                activity_text = f"{activity:.2f}"
            else:
                activity_text = str(activity)
            
            legend = (f"#{idx}\n"
                     f"ç›¸ä¼¼åº¦: {similarity:.3f}\n"
                     f"pIC50: {activity_text}")
            legends.append(legend)
        
        mols_to_draw = [query_mol] + top_molecules_df["ROMol"].tolist()
        
        # ç”Ÿæˆåˆ†å­ç½‘æ ¼å›¾åƒ
        img = Draw.MolsToGridImage(
            mols=mols_to_draw,
            legends=legends,
            molsPerRow=n_mols_per_row,
            subImgSize=sub_img_size,
            useSVG=False,  # ä½¿ç”¨PNGæ ¼å¼ï¼Œé€‚åˆStreamlit
            returnPNG=True
        )
        
        # è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²
        buffered = BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return img_str

class AdvancedChemInsightEngine:
    """é«˜çº§åŒ–å­¦æ´å¯Ÿå¼•æ“ï¼ˆé›†æˆä¼˜åŒ–ç‰ˆT004å’ŒT033ï¼‰"""
    
    def __init__(self, reference_data_path: Optional[Path] = None):
        """
        æ™ºèƒ½åˆå§‹åŒ–ï¼šæ”¯æŒç¦»çº¿ã€ä¸Šä¼ ã€é›†æˆä¸‰ç§æ¨¡å¼ï¼Œç¡®ä¿æ°¸è¿œæœ‰å¯ç”¨çš„åˆ†æç»“æœ
        """
        self.config = ScreeningConfig()
        self.similarity_calc = AdvancedMolecularSimilarity(self.config)
        self.visualizer = AdvancedVisualization()
        self.reference_df = None
        self.data_mode = "offline"  # offline, uploaded, integrated
        
        # ä¼˜å…ˆçº§1: ç”¨æˆ·ä¸Šä¼ çš„æ•°æ®
        if reference_data_path and os.path.exists(reference_data_path):
            if self.load_reference_data(reference_data_path):
                self.data_mode = "uploaded"
        
        # ä¼˜å…ˆçº§2: é›†æˆé¡¹ç›®æ•°æ®
        elif self._find_project_data():
            self.data_mode = "integrated"
            
        # ä¼˜å…ˆçº§3: ç¦»çº¿æ¨¡å¼ï¼ˆæ€»æœ‰æ•°æ®ï¼‰
        else:
            self._load_offline_data()
            self.data_mode = "offline"
    
    def _load_offline_data(self):
        """ç¦»çº¿æ•°æ®ï¼šå†…ç½®ç¤ºä¾‹ + æ™ºèƒ½ç”Ÿæˆ"""
        import random
        
        # ç”Ÿæˆå¤šæ ·åŒ–çš„ç¤ºä¾‹åˆ†å­ï¼ˆEGFRç›¸å…³ç»“æ„ï¼‰
        offline_examples = [
            # EGFRæŠ‘åˆ¶å‰‚æ ¸å¿ƒéª¨æ¶
            {'smiles': 'Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1', 'activity': 8.2, 'name': 'EGFRæ ¸å¿ƒéª¨æ¶'},
            {'smiles': 'COC1=C(C=C2C(=C1)N=CN=C2C3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4', 'activity': 7.9, 'name': 'å‰éæ›¿å°¼ç±»ä¼¼ç‰©'},
            {'smiles': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 'activity': 4.5, 'name': 'å’–å•¡å› ï¼ˆé˜´æ€§å¯¹ç…§ï¼‰'},
            {'smiles': 'CC(=O)OC1=CC=CC=C1C(=O)O', 'activity': 3.8, 'name': 'é˜¿å¸åŒ¹æ—ï¼ˆé˜´æ€§å¯¹ç…§ï¼‰'},
            {'smiles': 'C1=CC=C(C=C1)C=O', 'activity': 5.2, 'name': 'è‹¯ç”²é†›'},
            # æ‰©å±•æ›´å¤šç¤ºä¾‹
            {'smiles': 'CC(C)NCC(O)COC1=CC=C(C=C1)CC(=O)N(C)C', 'activity': 6.7, 'name': 'æ¨¡æ‹ŸADMEä¼˜åŒ–'},
            {'smiles': 'O=C(NC1=CC=CC=C1)C2=CC=CN=C2', 'activity': 7.1, 'name': 'åŒç¯é…°èƒº'},
            {'smiles': 'NC(=O)C1=CC=C(OCCN2CCOCC2)C=C1', 'activity': 6.9, 'name': 'æŸ”æ€§è¿æ¥å­ç¤ºä¾‹'},
        ]
        
        # æ·»åŠ åŒ–å­¦è§„åˆ™ç”Ÿæˆçš„è™šæ‹Ÿåˆ†å­
        core_scaffolds = [
            'Nc1ncnc2cc3ccccc3cc12',  # å˜Œå‘¤ç±»ä¼¼ç‰©
            'O=C(Nc1ccccc1)c2cccnc2',  # èŠ³åŸºé…°èƒº
            'Cc1cc(C)c(/C=C2\\C(=O)Nc3ncnc(N)c32)oc1C',  # å¤æ‚å¤©ç„¶äº§ç‰©ç±»ä¼¼ç‰©
        ]
        
        for scaffold in core_scaffolds:
            # é€šè¿‡åŒ–å­¦è§„åˆ™ç”Ÿæˆå˜ä½“
            for _ in range(3):
                modified = self._generate_variant(scaffold)
                offline_examples.append({
                    'smiles': modified,
                    'activity': round(random.uniform(5.0, 8.5), 1),
                    'name': 'è§„åˆ™ç”Ÿæˆå˜ä½“'
                })
        
        self.reference_df = pd.DataFrame(offline_examples)
        self.reference_df['pIC50'] = self.reference_df['activity']
        self.reference_df['source'] = 'offline_demo'
        
        # æ·»åŠ åˆ†å­å¯¹è±¡åˆ—
        if "ROMol" not in self.reference_df.columns:
            PandasTools.AddMoleculeColumnToFrame(self.reference_df, "smiles")
        
        # è®¡ç®—æè¿°ç¬¦
        self.reference_df = self.similarity_calc.calculate_descriptors(self.reference_df)
    
    def _find_project_data(self):
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®å·²æœ‰çš„æ•°æ®æ–‡ä»¶"""
        possible_paths = [
            BASE_DIR / "egfr_compounds_clean.csv",
            BASE_DIR / "data" / "egfr_data.csv",
            BASE_DIR / "egfr_compounds.csv",
            BASE_DIR / "rf_egfr_model_final.pkl",
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                # å¦‚æœæ˜¯CSVï¼Œç›´æ¥åŠ è½½
                if path.suffix == '.csv':
                    try:
                        self.load_reference_data(path)
                        self.data_mode = "integrated"
                        return True
                    except Exception as e:
                        continue
                # å¦‚æœæ˜¯æ¨¡å‹æ–‡ä»¶ï¼Œæå–ç‰¹å¾ä¿¡æ¯
                elif path.suffix == '.pkl':
                    try:
                        self._extract_from_model(path)
                        self.data_mode = "integrated"
                        return True
                    except Exception:
                        continue
        
        return False
    
    def _extract_from_model(self, model_path):
        """ä»æ¨¡å‹æ–‡ä»¶ä¸­æå–è®­ç»ƒæ•°æ®ä¿¡æ¯"""
        import pickle
        
        with open(model_path, 'rb') as f:
            pickle.load(f)
        
        # å¦‚æœæ¨¡å‹åŒ…å«ç‰¹å¾åç§°ç­‰ä¿¡æ¯ï¼Œå¯ä»¥ç”¨äºæ„å»ºå‚è€ƒæ•°æ®
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼ŒåŠ è½½ç¦»çº¿æ•°æ®ä½œä¸ºå¤‡é€‰
        self._load_offline_data()
        self.reference_df['source'] = 'model_extracted'
    
    def _generate_variant(self, scaffold):
        """åŸºäºåŒ–å­¦è§„åˆ™ç”Ÿæˆåˆ†å­å˜ä½“"""
        mol = Chem.MolFromSmiles(scaffold)
        if not mol:
            return scaffold
        
        # ç®€å•çš„åŒ–å­¦å˜æ¢è§„åˆ™
        transforms = [
            lambda m: Chem.MolFromSmiles(m.ToSmiles().replace('C', 'N', 1)),
            lambda m: Chem.MolFromSmiles(m.ToSmiles().replace('=O', '=S', 1)),
            lambda m: Chem.MolFromSmiles(m.ToSmiles() + 'C'),
            lambda m: Chem.MolFromSmiles('CC' + m.ToSmiles()),
        ]
        
        try:
            transformed = random.choice(transforms)(mol)
            return Chem.MolToSmiles(transformed) if transformed else scaffold
        except:
            return scaffold
    
    def load_reference_data(self, data_path: Path) -> bool:
        """åŠ è½½å‚è€ƒæ•°æ®é›†ï¼ˆæ·»åŠ åˆ†å­å¯¹è±¡åˆ—ï¼‰"""
        try:
            self.reference_df = pd.read_csv(data_path)
            
            # æ£€æŸ¥å¿…è¦åˆ—
            required_cols = ["smiles"]
            missing_cols = [col for col in required_cols if col not in self.reference_df.columns]
            
            if missing_cols:
                st.error(f"æ•°æ®é›†ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return False
            
            # æ·»åŠ åˆ†å­å¯¹è±¡åˆ—
            if "ROMol" not in self.reference_df.columns:
                PandasTools.AddMoleculeColumnToFrame(self.reference_df, "smiles")
            
            # è®¡ç®—æè¿°ç¬¦
            self.reference_df = self.similarity_calc.calculate_descriptors(self.reference_df)
            
            st.sidebar.success(f"âœ… å‚è€ƒæ•°æ®é›†å·²åŠ è½½: {len(self.reference_df)} ä¸ªåˆ†å­")
            return True
            
        except Exception as e:
            st.error(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
            return False
    
    def perform_advanced_screening(self, 
                                 query_smiles: str,
                                 top_n: int = 10) -> Dict[str, Any]:
        """æ‰§è¡Œé«˜çº§ç›¸ä¼¼æ€§ç­›é€‰"""
        results = {
            "success": False,
            "query_smiles": query_smiles,
            "query_mol": None,
            "top_molecules": None,
            "statistics": None,
            "enrichment_data": None,
            "visualizations": {}
        }
        
        try:
            # 1. éªŒè¯æŸ¥è¯¢åˆ†å­
            query_mol = self.similarity_calc.smiles_to_mol(query_smiles)
            if query_mol is None:
                results["error"] = "æ— æ•ˆçš„SMILESå­—ç¬¦ä¸²"
                return results
            
            results["query_mol"] = query_mol
            
            if self.reference_df is None:
                results["error"] = "æœªåŠ è½½å‚è€ƒæ•°æ®é›†"
                return results
            
            # 2. è®¡ç®—ç›¸ä¼¼åº¦
            screened_df = self.similarity_calc.calculate_similarities(
                query_mol, self.reference_df
            )
            
            # 3. æ’åºå¹¶è·å–Top N
            screened_df = screened_df.sort_values(
                "tanimoto_morgan", ascending=False
            ).reset_index(drop=True)
            
            top_molecules = screened_df.head(top_n).copy()
            results["top_molecules"] = top_molecules
            
            # 4. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            results["statistics"] = self.similarity_calc.get_similarity_statistics(screened_df)
            
            # 5. ç”Ÿæˆå¯Œé›†æ•°æ®
            if "pIC50" in screened_df.columns:
                results["enrichment_data"] = self._generate_enrichment_data(
                    screened_df, "tanimoto_morgan"
                )
            
            # 6. ç”Ÿæˆå¯è§†åŒ–
            results["visualizations"]["similarity_distribution"] = \
                self.visualizer.visualize_similarity_distribution(screened_df)
            
            if "pIC50" in screened_df.columns:
                results["visualizations"]["enrichment_plot"] = \
                    self.visualizer.create_enrichment_plot(screened_df)
            
            results["visualizations"]["molecules_grid"] = \
                self.visualizer.visualize_top_molecules(query_mol, top_molecules)
            
            results["success"] = True
            
        except Exception as e:
            results["error"] = str(e)
            st.error(f"ç­›é€‰è¿‡ç¨‹å‡ºé”™: {e}")
        
        return results
    
    def _generate_enrichment_data(self, df: pd.DataFrame,
                                similarity_measure: str) -> pd.DataFrame:
        """ç”Ÿæˆå¯Œé›†æ•°æ®"""
        df_sorted = df.sort_values(similarity_measure, ascending=False).reset_index(drop=True)

        n_total = len(df_sorted)

        # æ£€æŸ¥pIC50åˆ—æ˜¯å¦å­˜åœ¨
        if "pIC50" not in df_sorted.columns:
            st.warning("æ•°æ®é›†ç¼ºå°‘pIC50åˆ—")
            return pd.DataFrame(columns=["%_ranked_dataset", "%_true_actives_identified"])

        n_actives = (df_sorted["pIC50"] >= self.config.pic50_cutoff).sum()

        # å¤„ç†æ— æ´»æ€§åˆ†å­çš„æƒ…å†µ
        if n_actives == 0:
            df_sorted["cumulative_actives"] = 0
            df_sorted["%_ranked_dataset"] = (df_sorted.index + 1) / n_total * 100
            df_sorted["%_true_actives_identified"] = 0.0
        else:
            df_sorted["cumulative_actives"] = (df_sorted["pIC50"] >= self.config.pic50_cutoff).cumsum()
            df_sorted["%_ranked_dataset"] = (df_sorted.index + 1) / n_total * 100
            df_sorted["%_true_actives_identified"] = df_sorted["cumulative_actives"] / n_actives * 100

        return df_sorted[["%_ranked_dataset", "%_true_actives_identified"]].copy()
    
    def calculate_enrichment_factors(self, df: pd.DataFrame,
                                   cutoff_percentages: List[float] = None) -> pd.DataFrame:
        """è®¡ç®—å¯Œé›†å› å­"""
        # æ£€æŸ¥pIC50åˆ—æ˜¯å¦å­˜åœ¨
        if "pIC50" not in df.columns:
            st.warning("æ•°æ®é›†ç¼ºå°‘pIC50åˆ—ï¼Œæ— æ³•è®¡ç®—å¯Œé›†å› å­")
            return pd.DataFrame()

        if cutoff_percentages is None:
            cutoff_percentages = [1, 2, 5, 10]

        results = []
        n_actives = (df["pIC50"] >= self.config.pic50_cutoff).sum()
        n_total = len(df)

        if n_actives == 0:
            st.warning("æ•°æ®é›†ä¸­æ²¡æœ‰æ´»æ€§åˆ†å­(pIC50 >= 6.3)ï¼Œæ— æ³•è®¡ç®—å¯Œé›†å› å­")
            return pd.DataFrame()

        ratio_actives = n_actives / n_total * 100  # æ´»æ€§åˆ†å­ç™¾åˆ†æ¯”

        for cutoff in cutoff_percentages:
            row = {"Cutoff_%": cutoff}

            for measure in ["tanimoto_maccs", "tanimoto_morgan"]:
                enrichment = self._generate_enrichment_data(df, measure)

                mask = enrichment["%_ranked_dataset"] <= cutoff
                if mask.any():
                    ef = enrichment.loc[mask, "%_true_actives_identified"].iloc[-1]
                    row[f"EF_{measure}"] = round(ef, 2)
                else:
                    row[f"EF_{measure}"] = 0.0

            # éšæœºEFï¼ˆåœ¨éšæœºç­›é€‰ä¸‹ï¼Œè¯†åˆ«çš„æ´»æ€§ç™¾åˆ†æ¯”ç­‰äºæ£€æŸ¥çš„æ•°æ®ç™¾åˆ†æ¯”ï¼‰
            row["EF_Random"] = cutoff

            # æœ€ä¼˜EFï¼šç†æƒ³æƒ…å†µä¸‹ï¼Œåœ¨æ£€æŸ¥æ‰€æœ‰æ´»æ€§åˆ†å­åè¯†åˆ«100%æ´»æ€§åˆ†å­
            # EF_Optimal = min(100 / ratio_actives, 100 / cutoff)
            if ratio_actives > 0:
                ef_optimal = min(100 / ratio_actives, 100 / cutoff)
                row["EF_Optimal"] = round(ef_optimal, 2)
            else:
                row["EF_Optimal"] = 0.0

            results.append(row)

        return pd.DataFrame(results)

def render_advanced_chem_insight():
    """åœ¨Streamlitä¸­æ¸²æŸ“é«˜çº§åŒ–å­¦æ´å¯Ÿç•Œé¢"""
    
    st.header("ğŸ”¬ é«˜çº§åŒ–å­¦æ´å¯Ÿåˆ†æ")
    st.markdown("""
    æä¾›ä¸“ä¸šçº§çš„é…ä½“ç›¸ä¼¼æ€§ç­›é€‰å’Œåˆ†æåŠŸèƒ½
    """)
    
    # åˆå§‹åŒ–å¼•æ“ï¼ˆæ™ºèƒ½åˆå§‹åŒ–ï¼Œç¡®ä¿æ€»æœ‰æ•°æ®ï¼‰
    engine = AdvancedChemInsightEngine()
    
    # æ•°æ®çŠ¶æ€æŒ‡ç¤ºå™¨
    col_status, col_upload = st.columns([2, 1])
    
    with col_status:
        mode_badges = {
            "offline": "ğŸ”˜ ç¦»çº¿æ¨¡å¼ï¼ˆç¤ºä¾‹æ•°æ®ï¼‰",
            "uploaded": "âœ… è‡ªå®šä¹‰æ•°æ®æ¨¡å¼",
            "integrated": "âš¡ é›†æˆæ•°æ®æ¨¡å¼"
        }
        
        st.info(f"**æ•°æ®æ¨¡å¼**: {mode_badges.get(engine.data_mode, 'ç¦»çº¿æ¨¡å¼')}")
        
        if engine.data_mode == "offline":
            st.caption("ğŸ’¡ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®å¯è·å¾—æ›´ç²¾å‡†åˆ†æ")
    
    with col_upload:
        with st.expander("ğŸ“ ä¸Šä¼ æ•°æ®", expanded=False):
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ CSVæ–‡ä»¶ï¼ˆåŒ…å«smilesåˆ—ï¼‰",
                type=['csv'],
                help="æ–‡ä»¶åº”åŒ…å«'smiles'åˆ—ï¼Œå¯é€‰'activity'ã€'pIC50'ç­‰æ´»æ€§åˆ—"
            )
            
            if uploaded_file:
                try:
                    user_df = pd.read_csv(uploaded_file)
                    if 'smiles' in user_df.columns:
                        data_path = Path("uploaded_reference_data.csv")
                        with open(data_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        
                        if engine.load_reference_data(data_path):
                            engine.data_mode = "uploaded"
                            st.success(f"âœ… å·²åŠ è½½ {len(user_df)} ä¸ªåˆ†å­")
                            
                            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                            with st.expander("é¢„è§ˆæ•°æ®"):
                                st.dataframe(user_df.head())
                    else:
                        st.error("CSVå¿…é¡»åŒ…å«'smiles'åˆ—")
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    # è·å–æŸ¥è¯¢åˆ†å­
    col1, col2 = st.columns([3, 1])
    with col1:
        if 'last_smiles' in st.session_state and st.session_state.last_smiles:
            default_smiles = st.session_state.last_smiles
        else:
            default_smiles = "COC1=C(OCCCN2CCOCC2)C=C2C(NC3=CC(Cl)=C(F)C=C3)=NC=NC2=C1"
        
        query_smiles = st.text_area(
            "**è¾“å…¥æŸ¥è¯¢åˆ†å­SMILES**",
            value=default_smiles,
            height=100,
            help="è¾“å…¥è¦åˆ†æçš„åˆ†å­SMILESï¼Œå¦‚EGFRæŠ‘åˆ¶å‰‚Gefitinib"
        )
    
    with col2:
        st.subheader("âš™ï¸ ç­›é€‰å‚æ•°")
        top_n = st.slider("æ˜¾ç¤ºæ•°é‡", 5, 20, 10)
        st.slider("é«˜ç›¸ä¼¼åº¦é˜ˆå€¼", 0.1, 1.0, 0.7, 0.05, key="similarity_threshold")
        
        if st.button("ğŸš€ å¼€å§‹é«˜çº§åˆ†æ", type="primary", use_container_width=True):
            st.session_state["advanced_analysis_triggered"] = True
    
    # æ‰§è¡Œåˆ†æ
    if st.session_state.get("advanced_analysis_triggered", False) and query_smiles:
        with st.spinner("æ­£åœ¨è¿›è¡Œé«˜çº§åŒ–å­¦åˆ†æ..."):
            results = engine.perform_advanced_screening(
                query_smiles, top_n=top_n
            )
            
            if results["success"]:
                display_advanced_results(results, engine)
            else:
                st.error(f"åˆ†æå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")

def display_advanced_results(results: Dict, engine: AdvancedChemInsightEngine):
    """æ˜¾ç¤ºé«˜çº§åˆ†æç»“æœ"""
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š ç­›é€‰ç»“æœ", 
        "ğŸ“ˆ ç»Ÿè®¡åˆ†æ", 
        "ğŸ¯ å¯Œé›†åˆ†æ",
        "ğŸ§ª åˆ†å­å¯è§†åŒ–",
        "ğŸ§  æ™ºèƒ½è§£è¯»"
    ])
    
    with tab1:
        st.subheader("ç›¸ä¼¼æ€§ç­›é€‰ç»“æœ")
        
        # æ˜¾ç¤ºæ•°æ®æºè¯´æ˜
        if engine.data_mode == "offline":
            st.warning("""
            **å½“å‰ä½¿ç”¨ç¤ºä¾‹æ•°æ®**ï¼Œç»“æœåŸºäºåŒ–å­¦ç›¸ä¼¼æ€§åŸç†å±•ç¤ºã€‚
            ä¸Šä¼ çœŸå®EGFRæ•°æ®é›†å¯è·å¾—é’ˆå¯¹æ€§çš„ç²¾å‡†åˆ†æã€‚
            """)
        
        if results["top_molecules"] is not None:
            top_df = results["top_molecules"]
            
            # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
            col1, col2, col3, col4 = st.columns(4)
            stats = results["statistics"]
            
            col1.metric("æœ€é«˜ç›¸ä¼¼åº¦", f"{stats['morgan_max']:.3f}")
            col2.metric("å¹³å‡ç›¸ä¼¼åº¦", f"{stats['morgan_mean']:.3f}")
            col3.metric("é«˜ç›¸ä¼¼åº¦åˆ†å­", stats['high_similarity_count'])
            col4.metric("é«˜ç›¸ä¼¼åº¦æ´»æ€§åˆ†å­", stats['active_high_similarity'])
            
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœè¡¨æ ¼ï¼ˆåŠ¨æ€é€‰æ‹©å¯ç”¨åˆ—ï¼‰
            available_cols = []
            column_mapping = {
                "molecule_chembl_id": "ChEMBL ID",
                "tanimoto_morgan": "Morganç›¸ä¼¼åº¦",
                "tanimoto_maccs": "MACCSç›¸ä¼¼åº¦",
                "pIC50": "æ´»æ€§å€¼",
                "molecule_weight": "åˆ†å­é‡",
                "logp": "LogP",
                "smiles": "SMILES"
            }

            for col in column_mapping.keys():
                if col in top_df.columns:
                    available_cols.append(col)

            if available_cols:
                display_df = top_df[available_cols].rename(columns=column_mapping)
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.warning("æ— æ³•æ˜¾ç¤ºè¯¦ç»†ç»“æœï¼šç¼ºå°‘å¿…è¦çš„åˆ—")
    
    with tab2:
        st.subheader("ç»Ÿè®¡åˆ†æ")
        
        if "similarity_distribution" in results["visualizations"]:
            fig = results["visualizations"]["similarity_distribution"]
            st.pyplot(fig)
            
            # ä¸‹è½½æŒ‰é’®
            buf = BytesIO()
            fig.savefig(buf, format="png", dpi=150, bbox_inches='tight')
            buf.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½åˆ†å¸ƒå›¾",
                data=buf,
                file_name="similarity_distribution.png",
                mime="image/png"
            )
        
        # å¯Œé›†å› å­è®¡ç®—
        if results["enrichment_data"] is not None and engine.reference_df is not None:
            st.subheader("å¯Œé›†å› å­åˆ†æ")
            
            ef_df = engine.calculate_enrichment_factors(engine.reference_df)
            st.dataframe(ef_df, use_container_width=True, hide_index=True)
    
    with tab3:
        st.subheader("å¯Œé›†æ›²çº¿åˆ†æ")
        
        if "enrichment_plot" in results["visualizations"]:
            fig = results["visualizations"]["enrichment_plot"]
            st.pyplot(fig)
            
            # è§£é‡Šå¯Œé›†æ›²çº¿
            with st.expander("ğŸ“– å¯Œé›†æ›²çº¿è§£è¯»æŒ‡å—"):
                st.markdown("""
                **å¯Œé›†æ›²çº¿è§£é‡Š**:
                - **è“è‰²æ›²çº¿**: å®é™…ç­›é€‰æ€§èƒ½
                - **ç»¿è‰²è™šçº¿**: ç†è®ºä¸Šé™ï¼ˆæœ€ä¼˜æ›²çº¿ï¼‰
                - **ç°è‰²ç‚¹çº¿**: éšæœºç­›é€‰åŸºçº¿
                
                **æ€§èƒ½è¯„ä¼°**:
                - æ›²çº¿è¶Šé è¿‘å·¦ä¸Šè§’ï¼Œç­›é€‰æ€§èƒ½è¶Šå¥½
                - æ—©æœŸå¯Œé›†å› å­(EF@1%) > 20è¡¨ç¤ºä¼˜ç§€ç­›é€‰èƒ½åŠ›
                - æ›²çº¿ä¸‹é¢ç§¯(AUC)è¶Šå¤§ï¼Œæ•´ä½“æ€§èƒ½è¶Šå¥½
                """)
    
    with tab4:
        st.subheader("åˆ†å­å¯è§†åŒ–")
        
        if "molecules_grid" in results["visualizations"]:
            img_str = results["visualizations"]["molecules_grid"]
            
            # æ˜¾ç¤ºåˆ†å­ç½‘æ ¼
            st.markdown(
                f'<img src="data:image/png;base64,{img_str}" width="100%">',
                unsafe_allow_html=True
            )
            
            # åŒ–å­¦æ„ä¹‰è§£è¯»
            st.subheader("ğŸ§ª åŒ–å­¦æ´å¯Ÿ")
            
            if results["top_molecules"] is not None and len(results["top_molecules"]) > 0:
                top_mol = results["top_molecules"].iloc[0]
                similarity = top_mol["tanimoto_morgan"]
                activity = top_mol.get("pIC50", None)
                
                if similarity > 0.8:
                    st.success("**ğŸ” å‘ç°é«˜åº¦ç›¸ä¼¼åˆ†å­**")
                    st.markdown("""
                    - æŸ¥è¯¢åˆ†å­ä¸å·²çŸ¥åŒ–åˆç‰©ç»“æ„é«˜åº¦ç›¸ä¼¼
                    - é¢„æµ‹ç»“æœå…·æœ‰å¼ºåŒ–å­¦ä¾æ®
                    - å»ºè®®è¿›ä¸€æ­¥éªŒè¯ç»“åˆæ¨¡å¼å’Œè¯æ•ˆå›¢åŒ¹é…
                    """)
                
                if activity and activity >= 6.3:
                    st.info(f"**ğŸ¯ å‘ç°æ´»æ€§ç±»ä¼¼ç‰©** (pIC50 = {activity:.2f})")
                    st.markdown("""
                    - ç›¸ä¼¼åˆ†å­å…·æœ‰å·²çŸ¥æ´»æ€§
                    - æ”¯æŒåŸºäºç›¸ä¼¼æ€§çš„æ´»æ€§é¢„æµ‹
                    - å¯ä½œä¸ºå…ˆå¯¼åŒ–åˆç‰©ä¼˜åŒ–çš„èµ·ç‚¹
                    """)
    
    with tab5:
        st.subheader("ğŸ§  æ™ºèƒ½åŒ–å­¦è§£è¯»")
        
        # è·å–æŸ¥è¯¢SMILES
        query_smiles = results.get('query_smiles', '')
        
        # åŸºäºè§„åˆ™çš„åˆ†æï¼Œä¸ä¾èµ–å¤–éƒ¨æ•°æ®
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**åŸºäºåŒ–å­¦è§„åˆ™çš„åˆ†æ**")
            
            # 1. å­ç»“æ„è¯†åˆ«
            if query_smiles:
                mol = engine.similarity_calc.smiles_to_mol(query_smiles)
                if mol:
                    # è¯†åˆ«å¸¸è§è¯æ•ˆå›¢
                    pharmacophores = identify_pharmacophores(mol)
                    st.write("**è¯†åˆ«åˆ°çš„æ½œåœ¨è¯æ•ˆå›¢:**")
                    for pharma in pharmacophores:
                        st.write(f"â€¢ {pharma}")
        
        with col2:
            st.markdown("**åˆ†å­æ€§è´¨è¯„ä¼°**")
            
            if query_smiles:
                # è®¡ç®—åŸºæœ¬æ€§è´¨
                props = calculate_molecular_properties(query_smiles)
                
                st.metric("åˆ†å­é‡", f"{props.get('mw', 0):.1f}")
                st.metric("è„‚æ°´åˆ†é…ç³»æ•°(LogP)", f"{props.get('logp', 0):.2f}")
                st.metric("æ°¢é”®ä¾›ä½“", props.get('hbd', 0))
                st.metric("æ°¢é”®å—ä½“", props.get('hba', 0))


def identify_pharmacophores(mol: Chem.rdchem.Mol) -> List[str]:
    """è¯†åˆ«åˆ†å­ä¸­çš„å¸¸è§è¯æ•ˆå›¢"""
    from rdkit.Chem import Fragments
    
    pharmacophores = []
    
    # æ£€æŸ¥èŠ³é¦™ç¯
    num_aromatic_rings = Fragments.fr_benzene(mol) + Fragments.fr_aniline(mol)
    if num_aromatic_rings > 0:
        pharmacophores.append(f"èŠ³é¦™ç¯ç³»ç»Ÿ ({num_aromatic_rings}ä¸ª)")
    
    # æ£€æŸ¥æ°¢é”®å—ä½“
    num_acceptors = Fragments.fr_NH0(mol) + Fragments.fr_NH1(mol) + Fragments.fr_NH2(mol)
    if num_acceptors > 0:
        pharmacophores.append(f"æ°¢é”®å—ä½“ ({num_acceptors}ä¸ª)")
    
    # æ£€æŸ¥æ°¢é”®ä¾›ä½“
    num_donors = Fragments.fr_NH1(mol) + Fragments.fr_NH2(mol)
    if num_donors > 0:
        pharmacophores.append(f"æ°¢é”®ä¾›ä½“ ({num_donors}ä¸ª)")
    
    # æ£€æŸ¥å¤ç´ 
    if Fragments.fr_halogen(mol) > 0:
        pharmacophores.append("å¤ç´ åŸå­")
    
    # æ£€æŸ¥é…°èƒº
    if Fragments.fr_amide(mol) > 0:
        pharmacophores.append("é…°èƒºåŸºå›¢")
    
    # æ£€æŸ¥ç¡åŸº
    if Fragments.fr_nitro(mol) > 0:
        pharmacophores.append("ç¡åŸº")
    
    if not pharmacophores:
        pharmacophores.append("æœªè¯†åˆ«åˆ°å¸¸è§è¯æ•ˆå›¢")
    
    return pharmacophores


def calculate_molecular_properties(smiles: str) -> Dict[str, float]:
    """è®¡ç®—åˆ†å­çš„åŸºæœ¬ç†åŒ–æ€§è´¨"""
    mol = Chem.MolFromSmiles(smiles)
    if not mol:
        return {}
    
    props = {
        'mw': Descriptors.MolWt(mol),
        'logp': Descriptors.MolLogP(mol),
        'hbd': Descriptors.NumHDonors(mol),
        'hba': Descriptors.NumHAcceptors(mol),
        'tpsa': Descriptors.TPSA(mol),
        'rotb': Descriptors.NumRotatableBonds(mol),
        'aromatic_rings': Descriptors.NumAromaticRings(mol),
    }
    
    return props

# ç‹¬ç«‹è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    st.set_page_config(
        page_title="é«˜çº§åŒ–å­¦æ´å¯Ÿæ¨¡å—", 
        layout="wide",
        initial_sidebar_state="expanded"
    )
    render_advanced_chem_insight()